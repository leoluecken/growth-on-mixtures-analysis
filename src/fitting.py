import os
from pathlib import Path
import pickle
from pprint import pp

import pandas as pd
import numpy as np
import multiprocessing as mp
from scipy.interpolate import interp1d
from scipy.optimize import minimize
from scipy.integrate import solve_ivp
from scipy import cluster

import utils
import dynamics
import plotting
import defaults
from warnings import warn
from time import sleep
from itertools import starmap
from copy import deepcopy
from functools import reduce
from dynamics import generate_OU_traj
from config import NCPU, TMP_SAVE_DIR
from scipy.stats._qmc import LatinHypercube
from collections import defaultdict

## Weights for fitting routines
# Weighting for CDW
X_WEIGHT = 1.0
# Weighting for substrate concentration
S_WEIGHT = 1.0

# Whether TDA should be fitted along growth
TDA_FITTING = False
# Weighting for TDA
TDA_WEIGTH = 0.01

# Relative weighting for specific rate fits as compared to direct observables \in [0,1]
RATES_WEIGHT = 1.0

# Minimal value for CDWOD to calculate specific rates from (very fuzzy for initial small CDWOD)
MIN_CDWOD_RATES = 0.03

# Relative weighting for CDW and CDWOD based data
# e.g. the normalized residual error for the biomass rates is calculated as 
#      RATES_WEIGHT*(CDWOD_WEIGHT*normres(cdw_sim, cdwod)+CDW_WEIGHT*normres(cdw_sim, cdw))
# @see residualErrors()
CDWOD_WEIGHT = 1.0
CDW_WEIGHT = 0.0
assert(CDWOD_WEIGHT+CDW_WEIGHT==1)

OPTIMIZATION_METHOD = "Powell"
#OPTIMIZATION_OPTIONS = {"xtol":1e-5, "ftol":1e-5}
OPTIMIZATION_OPTIONS = {"xtol":1e-9, "ftol":1e-9}
INTEGRATION_METHOD = "Radau" # stiff

class DEBFitter(object):
    '''
    classdocs
    '''

    def __init__(self, experiment, params):
        print("Creating DEBFitter\nparams:", params)
        
        self._experiment = experiment
        self._dynamics = dynamics.DEBDynamics(params)
        self._tdaFitting  = TDA_FITTING
        self._fitK = params.get("fitK", True)
        self._V0 = params["V0"]
        self._substrates = params["substrates"]
        self._substrateIx = dict([(s,i) for i,s in enumerate(self._substrates)])
        
        # minimal indices for fitting specific rates (very 'jumpy' in initial phase with low biomass)
        # and maximal indices for fitting growth OD (OD assumed unreliable in stationary phase)
        self._ixMinRates, self._ixMaxGrowth = getIxMinAndIxMax(self._experiment, MIN_CDWOD_RATES)
        
        # Cache for similarities of substrate depletion curves (basis for clustering)
        self._substrateDissimilarities = {}
        # Clusters of similar substrates as generated by buildClusters() 
        self._substrateClusters = None
        # Threshold value for dissimilarity of substrates below which substrates are summarized within a cluster  
        self._similarityThreshold = 0.0
        # Whether this contains synthatic data
        self._synthetic=False
        
            
    def getID(self):
        return self._experiment.getID()
    def getRunIDs(self):
        return self._experiment._runIDs

    def getTSpan(self, rid):
        return self._experiment._tSpan[rid]
    def getTSpanRates(self, rid):
        return self._experiment._tSpanRates[rid]
    def getCDW(self, rid):
        return self._experiment._cdwSpan[rid]
    def getCDWOD(self, rid):
        return self._experiment._cdwodSpan[rid]
    def getTDA(self, rid):
        return self._experiment._tdaSpan[rid]
    def getS(self, rid):
        return self._experiment._sSpan[rid]
    def getCDWRates(self, rid):
        return self._experiment._cdwRates[rid]
    def getCDWODRates(self, rid):
        return self._experiment._cdwodRates[rid]
    def getTDARates(self, rid):
        return self._experiment._tdaRates[rid]
    def getSRates(self, rid):
        return self._experiment._sRates[rid]
    def getCDWRatesOD(self, rid):
        return self._experiment._cdwRatesOD[rid]
    def getCDWODRatesOD(self, rid):
        return self._experiment._cdwodRatesOD[rid]
    def getTDARatesOD(self, rid):
        return self._experiment._tdaRatesOD[rid]
    def getSRatesOD(self, rid):
        return self._experiment._sRatesOD[rid]
    def getClusters(self, cID=None):
        if cID is None:
            return self._substrateClusters
        else:
            return self._substrateClusters[cID]
    def getSubstrates(self):
        return self._substrates
    def getSubstrateIx(self, sid=None):
        if sid is None:
            return self._substrateIx
        else:
            return self._substrateIx[sid]
    def getExperiment(self):
        return self._experiment
    
    def setClusters(self, clusters):
        # semantics: clusterIndices = self._substrateClusters[clusterID]
        self._substrateClusters = clusters
    
    def getClusterIndices(self, cid):
        return deepcopy(self._substrateClusters[cid])
    
    
    def setGrowthParams(self, growthParams):
        self._dynamics.setGrowthParams(growthParams)
        
        if "V0" in growthParams:
            if self.getID() in growthParams["V0"]:
                self.setV0(growthParams["V0"][self.getID()])
            else:
                self.setV0(growthParams["V0"])
        
    def getGrowthParams(self):
        return self._dynamics.getGrowthParams()
    
    def setUptakeParams(self, params):
        pars_by_subs = defaultdict(dict)
        if "mu" in params and type(params["mu"]) != dict:
            if type(params["mu"]) is np.float64:
                mus = [params["mu"]]
            else:
                mus = params["mu"]
            for s, mu in zip(self._substrates, mus):
                pars_by_subs[s]["mu"] = mu
                    
        if "K" in params and type(params["K"]) != dict:
            if type(params["K"]) is np.float64:
                Ks = [params["K"]]
            else:
                Ks = params["K"]
            for s, K in zip(self._substrates, Ks):
                pars_by_subs[s]["K"] = K
        
        if pars_by_subs == {}:
            self._dynamics.setUptakeParams(params)
        else:
            self._dynamics.setUptakeParams(pars_by_subs)
    
    def getUptakeParams(self, sid=None):
        return self._dynamics.getUptakeParams(sid)
        
    def setV0(self, V0):
        if type(V0) == dict:
            self._V0 = V0
        else:
            assert(len(V0)==len(self.getRunIDs()))
            self._V0 = {rid:v0 for rid, v0 in zip(self.getRunIDs(), V0)}

    def getV0(self, rid=None):
        if rid:
            return self._V0[rid]
        else:
            return self._V0
    
    def activateInteractions(self):
        self._dynamics.activateInteractions()
    def deactivateInteractions(self):
        self._dynamics.deactivateInteractions()
    
    def resetInteractions(self):
        self._dynamics.resetInteractions()
    def setInteractions(self, interactions):
        # interactions is a map (substrateID -> [(a, clusterIndices),..])
        self._dynamics.setInteractions(interactions)
    def getInteractions(self):
        return self._dynamics.getInteractions()
    
    def interactionsActive(self):
        return self._dynamics.interactionsActive()
        
    def makeCDWinterpolation(self,rid):
        return interp1d(self.getTSpan(rid), self.getCDWOD(rid), fill_value="extrapolate")
    
    def generateSubstrateSolution(self, sid, rid):
        iPolV = self.makeCDWinterpolation(rid)
        self._dynamics.setVInterpolation(rid, iPolV)
        if self._dynamics.interactionsActive():
            iPolS = [interp1d(self.getTSpan(rid), self.getS(rid)[s], fill_value="extrapolate") for s in self._substrates]
            self._dynamics.setSInterpolation(rid, iPolS)
        self._dynamics.setActiveRunID(rid)
        S0 = [self.getS(rid)[sid][0]]
        T = (self.getTSpan(rid)[0], self.getTSpan(rid)[-1])
        six = self._substrateIx[sid]
        def f(t,s): return self._dynamics.uptakeWithGivenBiomass(t,s,six)
        sol = solve_ivp(f, T, S0,
                  t_eval=self.getTSpan(rid), method=INTEGRATION_METHOD, dense_output=True)
        return sol, f
        
            
    def generateBiomassSolution(self, rid, use_experimental_DS=False):
        # interpolate S from observations
        cdwodSpanRates = (self.getCDWOD(rid)[1:]+self.getCDWOD(rid)[:-1])*0.5
        sAbsRates = dict([(s, self.getSRatesOD(rid)[s]*cdwodSpanRates) for s in self._substrates])
        iPolDSV = [interp1d(self.getTSpanRates(rid), sAbsRates[s], fill_value="extrapolate") for s in self._substrates]
        self._dynamics.setDSInterpolation(rid, iPolDSV)
        iPolS = [interp1d(self.getTSpan(rid), self.getS(rid)[s], fill_value="extrapolate") for s in self._substrates]
        self._dynamics.setSInterpolation(rid, iPolS)

        self._dynamics.setActiveRunID(rid)
        V0 = self._V0[rid]
        # Number of timesteps to avg initial substrate rates
        nAvg = 1
        sSpan = self.getS(rid)
        S0 = np.array([sSpan[s][0] for s in self._substrates])
        P0 = self.getTDA(rid)[0]
        E0 = self._dynamics.getStationaryReserve(V0, S0)
        
        if use_experimental_DS:
            # Average substrate usage for first nAvg timesteps
            DS0 = np.array([np.nanmean((self.getSRatesOD(rid)[s][:nAvg]*cdwodSpanRates[:nAvg])) for s in self._substrates])
            E0 = self._dynamics.getStationaryReserve(V0, S0, DS0)
        else:
            E0 = self._dynamics.getStationaryReserve(V0, S0)
        T = (self.getTSpan(rid)[0], self.getTSpan(rid)[-1])
        y0 = [V0, E0, P0] if self._tdaFitting else [V0, E0]
        sol = solve_ivp(self._dynamics.growthWithGivenSubstrate, T, y0, 
                  t_eval=self.getTSpan(rid), method=INTEGRATION_METHOD, dense_output=True)         
        return sol, self._dynamics.growthWithGivenSubstrate


    def generateFullSolution(self, rid, includeTDA, parameter_noise=None, noise_rng=None):
        V0 = self._V0[rid]
        sSpan = self.getS(rid)
        S0 = [sSpan[s][0] for s in self._substrates]
        if includeTDA:
            P0 = self.getTDA(rid)[0]

        E0 = self._dynamics.getStationaryReserve(V0, S0)
        T = (self.getTSpan(rid)[0], self.getTSpan(rid)[-1])
        
        if includeTDA:
            self._dynamics.activateP()
        else:
            self._dynamics.deactivateP()
        
        X0 = np.hstack((V0, E0, S0))
        
        if parameter_noise and (rid not in self._dynamics._parameter_perturbations):
            self._dynamics.setParameterNoise(rid, parameter_noise, noise_rng, T)
            
        self._dynamics.setActiveRunID(rid)
        sol = solve_ivp(self._dynamics, T, X0, 
              t_eval=self.getTSpan(rid), method=INTEGRATION_METHOD, dense_output=True)

        return sol, self._dynamics
        

    def residualErrorFull(self, rid, plot=False):
        sol, rhs = self.generateFullSolution(rid, self._tdaFitting)
        
        maxix = self._ixMaxGrowth[rid]
        minix = self._ixMinRates[rid]
        
        solV = sol.y[0][:maxix]
        solE = sol.y[1][:maxix]
        if self._tdaFitting:
            solTDA = sol.y[2][:maxix]
            six1 = 3
        else:
            six1 = 2
        solS = sol.y[six1:, :maxix]
        
        solSpanRatesFull = sol.sol(self.getTSpanRates(rid))

        sExp = np.array([self.getS(rid)[sid][:maxix] for sid in self._substrates])
        cdwExp = self.getCDW(rid)[:maxix]
        cdwodExp = self.getCDWOD(rid)[:maxix]
        sRatesExp = np.array([self.getSRates(rid)[sid][minix:maxix] for sid in self._substrates])
        cdwRatesExp = self.getCDWRates(rid)[minix:maxix]
        cdwodRatesExp = self.getCDWODRates(rid)[minix:maxix]
        sRatesODExp = np.array([self.getSRatesOD(rid)[sid][minix:maxix] for sid in self._substrates])
        cdwRatesODExp = self.getCDWRatesOD(rid)[minix:maxix]
        cdwodRatesODExp = self.getCDWODRatesOD(rid)[minix:maxix]
        
        tSpanRatesFull = self.getTSpanRates(rid)
        tSpanRates = tSpanRatesFull[minix:maxix]
        
        solRatesFull = np.array([rhs(t,x)/x[0] for t, x in zip(tSpanRatesFull, solSpanRatesFull.T)]).T
        solRates = solRatesFull.T[minix:maxix].T
        solSRatesFull = solRatesFull[six1:]
        solSRates = solRates[six1:]
        solVRates = solRates[0]
        #print("solRatesFull: %s"%solRatesFull)

        if self._tdaFitting :
            tdaExp = self.getTDA(rid)
            tdaRatesExp = self.getTDARates(rid)[minix:maxix]
            tdaRatesODExp = self.getTDARatesOD(rid)[minix:maxix]
            solTDARates = solRates[2]

        nObs = maxix
        nCDW = nObs - np.count_nonzero(np.isnan(sRatesExp))

        sFac = 1./(np.nanmax(sExp)*nCDW)
        sRatesFac = CDW_WEIGHT*RATES_WEIGHT*S_WEIGHT/(np.nanmax(-sRatesExp)*nCDW)
        sRatesODFac = CDWOD_WEIGHT*RATES_WEIGHT*S_WEIGHT/(np.nanmax(-sRatesODExp)*nObs)

        cdwFac = CDW_WEIGHT*X_WEIGHT/(np.nanmax(cdwExp)*nCDW)
        cdwRatesFac = CDW_WEIGHT*CDW_WEIGHT*RATES_WEIGHT*X_WEIGHT/(np.nanmax(cdwRatesExp)*nCDW)
        cdwRatesODFac = CDWOD_WEIGHT*CDW_WEIGHT*RATES_WEIGHT*X_WEIGHT/(np.nanmax(cdwRatesODExp)*nCDW)
        
        cdwodFac = CDWOD_WEIGHT*X_WEIGHT/(np.nanmax(cdwodExp)*nObs)
        cdwodRatesFac = CDW_WEIGHT*CDWOD_WEIGHT*RATES_WEIGHT*X_WEIGHT/(np.nanmax(cdwodRatesExp)*nCDW)
        cdwodRatesODFac = CDWOD_WEIGHT*CDWOD_WEIGHT*RATES_WEIGHT*X_WEIGHT/(np.nanmax(cdwodRatesODExp)*nObs)
        
        if self._tdaFitting :    
            tdaFac = TDA_WEIGTH/(np.nanmax(tdaExp)*nObs)
            tdaRatesFac = CDW_WEIGHT*TDA_WEIGTH*RATES_WEIGHT/(np.nanmax(tdaRatesExp)*nCDW)
            tdaRatesODFac = CDWOD_WEIGHT*TDA_WEIGTH*RATES_WEIGHT/(np.nanmax(tdaRatesODExp)*nObs)
            
        SSR1, SST1 = 0.0, 0.0 
        SSR1 += sFac*np.nansum((sExp - solS)**2)
        SST1 += sFac*np.nansum((sExp - np.nanmean(sExp))**2)
        SSR1 += cdwFac*np.nansum((cdwExp - solV)**2)
        SST1 += cdwFac*np.nansum((cdwExp - np.nanmean(cdwExp))**2)
        SSR1 += cdwodFac*np.nansum((cdwodExp - solV)**2)
        SST1 += cdwodFac*np.nansum((cdwodExp - np.nanmean(cdwodExp))**2)
        if self._tdaFitting :
            SSR1 += tdaFac*np.nansum((tdaExp - solTDA)**2)
            SST1 += tdaFac*np.nansum((tdaExp - np.nanmean(tdaExp))**2)

        SSR2, SST2 = 0.0, 0.0 
        SSR2 += sRatesFac*np.nansum((sRatesExp - solSRates)**2)
        SST2 += sRatesFac*np.nansum((sRatesExp - np.nanmean(sRatesExp))**2)
        SSR2 += cdwRatesFac*np.nansum((cdwRatesExp - solVRates)**2)
        SST2 += cdwRatesFac*np.nansum((cdwRatesExp - np.nanmean(cdwRatesExp))**2)
        SSR2 += cdwodRatesFac*np.nansum((cdwodRatesExp - solVRates)**2)
        SST2 += cdwodRatesFac*np.nansum((cdwodRatesExp - np.nanmean(cdwodRatesExp))**2)
        if self._tdaFitting :
            SSR2 += tdaRatesFac*np.nansum((tdaRatesExp - solTDARates)**2)
            SST2 += tdaRatesFac*np.nansum((tdaRatesExp - np.nanmean(tdaRatesExp))**2)
        
        SSR3, SST3 = 0.0, 0.0 
        SSR3 += sRatesODFac*np.nansum((sRatesODExp - solSRates)**2)
        SST3 += sRatesODFac*np.nansum((sRatesODExp - np.nanmean(sRatesODExp))**2)
        SSR3 += cdwRatesODFac*np.nansum((cdwRatesODExp - solVRates)**2)
        SST3 += cdwRatesODFac*np.nansum((cdwRatesODExp - np.nanmean(cdwRatesODExp))**2)
        SSR3 += cdwodRatesODFac*np.nansum((cdwodRatesODExp - solVRates)**2)
        SST3 += cdwodRatesODFac*np.nansum((cdwodRatesODExp - np.nanmean(cdwodRatesODExp))**2)
        if self._tdaFitting :
            SSR3 += tdaRatesODFac*np.nansum((tdaRatesODExp - solTDARates)**2)
            SST3 += tdaRatesODFac*np.nansum((tdaRatesODExp - np.nanmean(tdaRatesODExp))**2)

        SSR, SST = sum([SSR1, SSR2, SSR3]), sum([SST1, SST2, SST3])

        if plot:
            import matplotlib.pyplot as plt
            import config
            plt.close('all')
            solT = sol.t[:maxix]
            plt.figure()
            axSubs = plt.subplot(211)
            axCDW = plt.twinx(axSubs)
            axSubRates = plt.subplot(212)
            axCDWRates = plt.twinx(axSubRates)
            for s in self._substrates:
                six = self._substrateIx[s]
                facS = 1.0
                axSubs.plot(sol.t, facS*sol.y[six1+six], color=config.substrate_colors[s], lw=0.3)
                sspan = self.getS(rid)[s]
                axSubs.plot(self.getTSpan(rid), facS*sspan, marker="x", ls="--", label="%s (exp)"%s, color=config.substrate_colors[s], lw=0.2)
                axSubs.plot(solT, facS*solS[six], label="%s (sim)"%s, color=config.substrate_colors[s])
                axSubRates.plot(tSpanRatesFull, solSRatesFull[six], color=config.substrate_colors[s], lw=0.3)
                axSubRates.plot(tSpanRates, solSRates[six], label="[dS/dt] (%s, sim)"%s, color=config.substrate_colors[s])
            axSubRates.plot(tSpanRatesFull, solRatesFull[0], color=config.substrate_colors["CDW"], lw=0.3)
            axSubRates.plot(tSpanRates, sRatesODExp[six], label="[ds/dt] (%s, exp, od)"%s, color=config.substrate_colors[s], marker="x", ls=":", lw=0.2)
            axSubRates.plot(tSpanRates, solRates[0], label="[dV/dt] (sim)", color=config.substrate_colors["CDW"])
            axSubRates.legend()
            axCDWRates.plot(tSpanRates, cdwRatesODExp, label="[dV/dt] (exp, od)", color=config.substrate_colors["CDW"], marker="x", ls=":", lw=0.2)
            if self._tdaFitting :
                axCDWRates.plot(tSpanRatesFull, solRatesFull[2], color=config.substrate_colors["TDA"], lw=0.3)
                axCDWRates.plot(tSpanRates, solRates[2], label="[dP/dt] (sim)", color=config.substrate_colors["TDA"])
                axCDWRates.plot(tSpanRates, tdaRatesExp, label="[dP/dt] (exp, cdw)", color=config.substrate_colors["TDA"], marker="x", lw=0.2)
                axCDWRates.plot(tSpanRates, tdaRatesODExp, label="[dP/dt] (exp, od)", color=config.substrate_colors["TDA"], marker="x", ls=":", lw=0.2)
            axCDWRates.legend()
            facE = np.nanmax(solV)/np.nanmax(solE/solV)
            axCDW.plot(sol.t, sol.y[0], color=config.substrate_colors["CDW"], lw=0.3)
            axCDW.plot(sol.t, facE*sol.y[1], color=config.substrate_colors["E"], lw=0.3)
            axCDW.plot(self.getTSpan(rid), self.getCDWOD(rid), marker="x", label="CDWOD (exp)", color="grey", lw=0.2)
            axCDW.plot(solT, solV, label="V (sim)", color=config.substrate_colors["CDW"])
            axCDW.plot(solT, facE*solE/solV, label="[E] (sim)", lw=0.5, color=config.substrate_colors["E"])
            if self._tdaFitting:
                axCDW.plot(sol.t, sol.y[2], color=config.substrate_colors["TDA"], lw=0.3)
                axCDW.plot(self.getTSpan(rid), self.getTDA(rid), marker="x", ls="--", label="TDA (exp)", color=config.substrate_colors["TDA"], lw=0.2)
                axCDW.plot(solT, solTDA, label="TDA (sim)", color=config.substrate_colors["TDA"])
            plt.title("%s, run %s, R2=%f"%(s, rid, 1-SSR/SST))
            utils.align_yaxis(axSubs, axCDW)
            axSubs.legend()
            axCDW.legend()
            plt.show()

        return SSR, SST
        
    def residualErrorUptake(self, rid, sid, plot=False, fn=None):
        sol, rhs = self.generateSubstrateSolution(sid, rid)
        
        solS = sol.y[0][:self._ixMaxGrowth[rid]]
        solSpanRatesFull = sol.sol(self.getTSpanRates(rid))
        
        sExp = self.getS(rid)[sid][:self._ixMaxGrowth[rid]]
        sRatesExp = self.getSRates(rid)[sid][self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        sRatesODExp = self.getSRatesOD(rid)[sid][self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        
        tSpanRatesFull = self.getTSpanRates(rid)
        tSpanRates = tSpanRatesFull[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        
        iPolV = self._dynamics._iPolV[rid](tSpanRatesFull)
        solSRatesFull = np.array([rhs(t,s)/v for t, s, v in zip(tSpanRatesFull, solSpanRatesFull.T, iPolV)]).T
        solSRates = solSRatesFull.T[self._ixMinRates[rid]:self._ixMaxGrowth[rid]].T

        nObs = len(sRatesExp)
        nCDW = nObs - np.count_nonzero(np.isnan(sRatesExp))

        sFac = 1./(np.nanmax(sExp)*nCDW)
        sRatesFac = CDW_WEIGHT*RATES_WEIGHT/(np.nanmax(-sRatesExp)*nCDW)
        sRatesODFac = CDWOD_WEIGHT*RATES_WEIGHT/(np.nanmax(-sRatesODExp)*nObs)
        
        # Errors wrt S uptake curve
        SSR1, SST1 = 0.0, 0.0 
        SSR1 += sFac*np.nansum((sExp - solS)**2)
        SST1 += sFac*np.nansum((sExp - np.nanmean(sExp))**2)

        # Errors wrt S/CDW rates
        SSR2, SST2 = 0.0, 0.0 
        SSR2 += sRatesFac*np.nansum((sRatesExp - solSRates)**2)
        SST2 += sRatesFac*np.nansum((sRatesExp - np.nanmean(sRatesExp))**2)
        
        # Errors wrt S/CDW rates
        SSR3, SST3 = 0.0, 0.0 
        SSR3 += sRatesODFac*np.nansum((sRatesODExp - solSRates)**2)
        SST3 += sRatesODFac*np.nansum((sRatesODExp - np.nanmean(sRatesODExp))**2)
        
        SSR, SST = sum([SSR1, SSR2, SSR3]), sum([SST1, SST2, SST3])

        if plot:
            title = "%s, run %s, R2=%f"%(sid, rid, 1-SSR/SST)
            plotting.plotSingleSubstrateUptakeFit(self, rid, sid, sol, rhs, title, fn)
        return SSR, SST    
        
        
    
    def residualErrorBiomass(self, rid, plot=False):
        sol, rhs = self.generateBiomassSolution(rid)
        
        solSpanRatesFull = sol.sol(self.getTSpanRates(rid))
        solV = sol.y[0][:self._ixMaxGrowth[rid]]
        
        cdwExp = self.getCDW(rid)[:self._ixMaxGrowth[rid]]
        cdwodExp = self.getCDWOD(rid)[:self._ixMaxGrowth[rid]]
        
        cdwRatesExp = self.getCDWRates(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        cdwodRatesExp = self.getCDWODRates(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
            
        cdwRatesODExp = self.getCDWRatesOD(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        cdwodRatesODExp = self.getCDWODRatesOD(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        
        tSpanRatesFull = self.getTSpanRates(rid)
        tSpanRates = tSpanRatesFull[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
        
        solRatesFull = np.array([rhs(t,sv)/sv[0] for t, sv in zip(tSpanRatesFull, solSpanRatesFull.T)]).T
        solRates = solRatesFull.T[self._ixMinRates[rid]:self._ixMaxGrowth[rid]].T
        solVRates = solRates[0]
        
        nObs = len(cdwExp)
        nCDW = nObs - np.count_nonzero(np.isnan(cdwExp))

        cdwFac = CDW_WEIGHT/(np.nanmax(cdwExp)*nCDW)
        cdwodFac = CDWOD_WEIGHT/(np.nanmax(cdwodExp)*nObs)
        
        cdwRatesFac = CDW_WEIGHT*CDW_WEIGHT*RATES_WEIGHT/(np.nanmax(cdwRatesExp)*nCDW)
        cdwodRatesFac = CDW_WEIGHT*CDWOD_WEIGHT*RATES_WEIGHT/(np.nanmax(cdwodRatesExp)*nCDW)

        cdwRatesODFac = CDWOD_WEIGHT*CDW_WEIGHT*RATES_WEIGHT/(np.nanmax(cdwRatesODExp)*nCDW)
        cdwodRatesODFac = CDWOD_WEIGHT*CDWOD_WEIGHT*RATES_WEIGHT/(np.nanmax(cdwodRatesODExp)*nObs)

        if self._tdaFitting :
            solTDA = sol.y[2]
            tdaExp = self.getTDA(rid)
            tdaRatesExp = self.getTDARates(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
            tdaRatesODExp = self.getTDARatesOD(rid)[self._ixMinRates[rid]:self._ixMaxGrowth[rid]]
            solTDARates = solRates[2]
            tdaFac = TDA_WEIGTH/(np.nanmax(tdaExp)*nObs)
            tdaRatesFac = CDW_WEIGHT*TDA_WEIGTH*RATES_WEIGHT/(np.nanmax(tdaRatesExp)*nCDW)
            tdaRatesODFac = CDWOD_WEIGHT*TDA_WEIGTH*RATES_WEIGHT/(np.nanmax(tdaRatesODExp)*nObs)

        # Errors wrt CDW growth curve
        SSR1, SST1 = 0.0, 0.0 
        SSR1 += cdwFac*np.nansum((cdwExp - solV)**2)
        SST1 += cdwFac*np.nansum((cdwExp - np.nanmean(cdwExp))**2)
        
        # Errors wrt CDWOD growth curve
        SSR1 += cdwodFac*np.nansum((cdwodExp - solV)**2)
        SST1 += cdwodFac*np.nansum((cdwodExp - np.nanmean(cdwodExp))**2)
        
        # Errors wrt TDA curve
        if self._tdaFitting :
            SSR1 += tdaFac*np.nansum((tdaExp - solTDA)**2)
            SST1 += tdaFac*np.nansum((tdaExp - np.nanmean(tdaExp))**2)
        
        # Errors wrt CDW/CDW rates
        SSR2, SST2 = 0.0, 0.0 
        SSR2 += cdwRatesFac*np.nansum((cdwRatesExp - solVRates)**2)
        SST2 += cdwRatesFac*np.nansum((cdwRatesExp - np.nanmean(cdwRatesExp))**2)
        # Errors wrt CDWOD/CDW rates
        SSR2 += cdwodRatesFac*np.nansum((cdwodRatesExp - solVRates)**2)
        SST2 += cdwodRatesFac*np.nansum((cdwodRatesExp - np.nanmean(cdwodRatesExp))**2)
        # Errors wrt TDA/CDW rates
        if self._tdaFitting :
            SSR2 += tdaRatesFac*np.nansum((tdaRatesExp - solTDARates)**2)
            SST2 += tdaRatesFac*np.nansum((tdaRatesExp - np.nanmean(tdaRatesExp))**2)
        
        # Errors wrt CDW/CDW rates
        SSR3, SST3 = 0.0, 0.0 
        SSR3 += cdwRatesODFac*np.nansum((cdwRatesODExp - solVRates)**2)
        SST3 += cdwRatesODFac*np.nansum((cdwRatesODExp - np.nanmean(cdwRatesODExp))**2)
        # Errors wrt CDWOD/CDW rates
        SSR3 += cdwodRatesODFac*np.nansum((cdwodRatesODExp - solVRates)**2)
        SST3 += cdwodRatesODFac*np.nansum((cdwodRatesODExp - np.nanmean(cdwodRatesODExp))**2)
        # Errors wrt TDA/CDW rates
        if self._tdaFitting :
            SSR3 += tdaRatesODFac*np.nansum((tdaRatesODExp - solTDARates)**2)
            SST3 += tdaRatesODFac*np.nansum((tdaRatesODExp - np.nanmean(tdaRatesODExp))**2)
        
        SSR, SST = sum([SSR1, SSR2, SSR3]), sum([SST1, SST2, SST3])
        
        if plot:
            import matplotlib.pyplot as plt
            import config
            solT = sol.t[:self._ixMaxGrowth[rid]]
            plt.figure()
            plt.subplot(211)
            plt.plot(sol.t, sol.y[0], color=config.substrate_colors["CDW"], lw=0.3)
            plt.plot(solT, solV, label="V (sim)", color=config.substrate_colors["CDW"], lw=1)
            plt.plot(self.getTSpan(rid), self.getCDWOD(rid), marker="x", label="CDWOD (exp)", color="grey")
            if self._tdaFitting :
                plt.plot(sol.t, solTDA, label="TDA (sim)", color=config.substrate_colors["TDA"], lw=1)            
                plt.plot(self.getTSpan(rid), self.getTDA(rid), marker="x", label="TDA (exp)", color=config.substrate_colors["TDA"])
            sSpan = np.array([self.getS(rid)[s] for s in self._substrates])
            plt.plot(self.getTSpan(rid), 0.1*sSpan.T, marker="x", label="%s (exp)"%self.getID(), color=config.substrate_colors[self.getID()])
            plt.title("%s, run %s, R2=%f"%(self.getID(), rid, 1-SSR/SST))
            plt.legend()
            
            plt.subplot(212)
            plt.plot(tSpanRatesFull, solRatesFull[0], color="grey", lw=0.3)
            plt.plot(tSpanRates, solRates[0], label="[dV/dt] (sim)", color="grey", lw=1)
            if self._tdaFitting :
                plt.plot(tSpanRatesFull, solRatesFull[2], color=config.substrate_colors["TDA"], lw=0.3)
                plt.plot(tSpanRates, solRates[2], label="[dP/dt] (sim)", color=config.substrate_colors["TDA"], lw=1)
                plt.plot(tSpanRates, tdaRatesExp, label="[dP/dt] (exp, cdw)", color=config.substrate_colors["TDA"], marker="x")
                plt.plot(tSpanRates, tdaRatesODExp, label="[dP/dt] (exp, od)", color=config.substrate_colors["TDA"], marker="x", ls=":")
            plt.plot(tSpanRates, cdwRatesExp, label="[dV/dt] (exp, cdw)", color=config.substrate_colors["CDW"], marker="x")
            plt.plot(tSpanRates, cdwRatesODExp, label="[dV/dt] (exp, od)", color=config.substrate_colors["CDW"], marker="x", ls=":")
            plt.legend()
        
        return SSR, SST    
    
    
    def getError(self, sid, params, clusterIDs=None, fitK=None):
        orig_pars = self.getUptakeParams(sid)
        self.setUptakeParams(params)
        err = self.fitUptakeParameter(sid, clusterIDs=clusterIDs, fitK=fitK, 
                                useInitialParams=True, returnInitialErrorOnly=True)
        return err 
    
        
    def fitUptakeParameter(self, sid, clusterIDs=None, fitK=None, useInitialParams=False,
                           returnInitialErrorOnly=False):
        # useInitialParams: indicates whether the fitter has been equipped with initial values for mu and K to start optimization from
        # returnInitialErrorOnly: Returns error value for initial parameter
        six=self._substrateIx[sid]
        if clusterIDs is not None:
            self._dynamics.activateInteractions()
            nInteractions = len(clusterIDs)
        else:
            self._dynamics.deactivateInteractions()
            nInteractions = 0
        
        if fitK is None:
            fitK = self._fitK
        
        # a_ix is the index of the first interaction parameter 
        # (depends on whether K is considered a free parameter,
        # because it will be the second if so.)
        a_ix = 2 if fitK else 1
        def Error(params):
            self._dynamics._mu[six] = params[0]
            if fitK:
                self._dynamics._K[six] = params[1]
            if clusterIDs is not None:
                self._dynamics._a[six] = ([], [])
                for i, clusterID in enumerate(clusterIDs):
                    clusterIndices = self._substrateClusters[clusterID]
                    a = params[a_ix+i]
                    self._dynamics._a[six][0].append(clusterIndices)
                    self._dynamics._a[six][1].append(a)
            SSR, SST = 0.0, 0.0
            for rid in self.getRunIDs():
                ssr, sst = self.residualErrorUptake(rid, sid)
                SSR+=ssr; SST+=sst
            return SSR, SST
        
        def minusR2(params):
            if np.min(params) < 0:
                return np.inf
            SSR, SST = Error(params)
            R2 = (1.0 - SSR/SST)
            if clusterIDs is None:
                print("%s: params: %s -> R2=%.9f"%(sid, params, R2))
            else:
                print("%s <- %s: params: %s -> R2=%.9f"%(sid, clusterIDs, params, R2))
            return - R2
            
        if useInitialParams:
            pars = self.getUptakeParams(sid)
            p0 = [pars["mu"]]
            if fitK:
                p0.append(pars["K"])
        else:
            pDict = defaults.makeParams([sid], len(self.getRunIDs()), self._synthetic)
            p0 = [pDict[sid]["mu"]]
            if fitK:
                p0.append(pDict[sid]["K"])
        for i in range(nInteractions):
            p0.append(defaults.uptakeParams["a_large"])
        
        if returnInitialErrorOnly:
            ssr0, sst0 = Error(np.array(p0))
            R2 = 1 - ssr0/sst0
            err0 = {"ssr":ssr0, "sst":sst0, "R2":R2}
            return err0
        
        # Reporting
        if clusterIDs is None:
            printHeader = "# %s"%sid
        else:
            printHeader = "# %s -> %s"%([self._substrateClusters[cID] for cID in clusterIDs], sid)
        
        fitFailed = False
        try:
            res = minimize(minusR2, np.array(p0), method=OPTIMIZATION_METHOD, options=OPTIMIZATION_OPTIONS)
            print(printHeader)                
            # Unify representation of optimal parameters as list even in univariational problem
            try: res.x[0]
            except: res.x = [res.x]
            
            ssr, sst = Error(res.x)
            R2 = 1 - ssr/sst
        except Exception as e:
            print(printHeader)
            print("Error!\n  Exception:", e)
            
            pOpt = {"mu":None, "K":None, "a":None, "yE":None}
            err = {"ssr":None, "sst":None}
            fitFailed = True
            R2 = -np.inf
            raise e
            
        if nInteractions > 0:
            # Run second fit with low initial interaction strengths (choose better fit below)
            for i in range(nInteractions):
                p0[-1-i] = defaults.uptakeParams["a_small"]
             
            try:
                res_smallA = minimize(minusR2, np.array(p0), method=OPTIMIZATION_METHOD, options=OPTIMIZATION_OPTIONS)  
                print(printHeader)                
                ssr_smallA, sst_smallA = Error(res_smallA.x)
                try: res_smallA.x[0]
                except: res_smallA.x = [res_smallA.x]
                R2_smallA = 1 - ssr_smallA/sst_smallA          
            except Exception as e:
                print(printHeader)
                print("Error!\n  Message:", str(e))
                R2_smallA = -np.inf
                fitFailed = True and fitFailed # fail if both attempts failed
                raise e
        
        if fitFailed:
            # both intial values failed to lead to good fit
            return {"pOpt":pOpt, "err":err}
            
        
        if clusterIDs is None:
            print("%s: "%(sid))
        else:
            print("%s <- %s: "%(sid, clusterIDs))
        if nInteractions > 0:
            if R2_smallA > R2:
                # small initial A gave the better fit!
                print("  Small initial a_ij gave a better fit: DR2 =", R2_smallA-R2)
                res = res_smallA
                R2 = R2_smallA
            else:
                # large initial A gave the better fit!
                print("  Large initial a_ij gave a better fit: DR2 =", R2-R2_smallA)
            
        
        pOpt = {"mu": res.x[0], "yE":self._dynamics._yE[six]}
        if fitK:
            pOpt["K"] = res.x[1]
        else:
            pOpt["K"] = self.getUptakeParams(sid)["K"]
        if clusterIDs is not None:
            pOpt["a"] = [res.x[a_ix+i] for i in range(nInteractions)]
        err ={"ssr":ssr, "sst":sst}
    
        print("  pOpt:",pOpt)
        print("  err:",err)
        print("  R2:", R2)

        return {"pOpt":pOpt, "err":err}
    
    
    def fitV0(self, onlyGrowthDynamics=False, rid = None):
        # fit V0 for biomass fit
        if rid is None:
            SSR, SST = 0.0, 0.0
            V0 = {}
            results = []
            
            # Sequential
            for rID in self._experiment._runIDs:
                results.append(self.fitV0(onlyGrowthDynamics, rID))
                
            for i, rID in enumerate(self._experiment._runIDs):
                ssr, sst, v0 = results[i]
                SSR+=ssr; SST+=sst
                V0[rID] = v0
            
            print("R2 (%s):"%self.getID(), 1.-SSR/SST)
            print("V0:", V0)
            return SSR, SST, V0
        else:
            def Error(v0, plot=False):
                self._V0[rid] = v0
                if onlyGrowthDynamics:
                    return self.residualErrorBiomass(rid, plot)
                else:
                    return self.residualErrorFull(rid, plot)
            def minusR2(v0):
                if v0<=0: return np.inf
                SSR, SST = Error(v0)
                R2 = (1.-SSR/SST)
                return -R2
            res = minimize(minusR2, defaults._defaultV0, method=OPTIMIZATION_METHOD, options=OPTIMIZATION_OPTIONS)
            V0 = res.x
            ssr, sst = Error(V0)
            # # Uncomment line below to enable diagnostic plotting
            return ssr, sst, V0
    
    
    def _makeDendrogram(self, dists, figname, showPlot=False):
        # generate and plot dendrogram        
        Z = cluster.hierarchy.linkage(dists, method="complete")
        print("Z:\n", Z)
        print("substrates:\n", dict(enumerate(self._substrates)))
        if figname is not None:
            import matplotlib.pyplot as plt
            plt.close("all")
        dgram = cluster.hierarchy.dendrogram(Z, labels=self._substrates, color_threshold=self._similarityThreshold)
        N = len(self._substrates)
        if figname is not None:
            plt.plot([0, N*N], [self._similarityThreshold,self._similarityThreshold], 'k--', lw=0.5)
            plt.title("Substrate clustering '%s'"%self.getID())
            plt.ylabel("Cluster distance")
            plt.gcf().set_size_inches((5,3))
            plt.gcf().savefig(figname)
            print("Written figure '%s'"%figname)
            if showPlot:
                plt.show()
            else:
                plt.close("all")
        return dgram
    
    def boundedIncrementClusters(self, Z, th):
        cluster_dists = Z[:,2]
        N = len(self._substrates)
        clusters = dict([(i, [i]) for i in range(N)])
        for i, d in enumerate(cluster_dists):
            if d > th:
                break
            cl1, cl2 = Z[i,:2]
            clusters[N+i] = []
            clusters[N+i].extend(clusters[cl1])
            clusters[N+i].extend(clusters[cl2])
            del clusters[cl1]
            del clusters[cl2]
        clusters = dict([(self._substrates[v[0]], v) for v  in clusters.values()])
        return clusters
    
    def _determineSubstrateClusters(self, dists, method="cut_tree"):
        Z = cluster.hierarchy.linkage(dists, method="complete")
        if method == "cut_tree":
            print("Using cut tree to determine clusters.")
            ct = cluster.hierarchy.cut_tree(Z, height = self._similarityThreshold)
            clusters = dict([(c, [i for i, x in enumerate(ct) if x[0]==c]) for c in np.unique(ct)])
            clusters = dict([(self._substrates[v[0]], v) for v  in clusters.values()])
            clusters_verb = dict([(c, [self._substrates[i] for i, x in enumerate(ct) if x[0]==c]) for c in np.unique(ct)])
            print("clusters:", clusters_verb)
        else:
            print("Using bounded diameter increment to determine clusters")
            print("Using self._similarityThreshold as max increment")
            clusters = self.boundedIncrementClusters(Z, self._similarityThreshold)
            print("clusters:", clusters)
        return clusters
    
    
    def _substrateDissimilarity(self, i, j):
        # Calculate similarity of substrates 
        # Check if a value was calculated already
        if i == j:
            return 0.0
        elif (i,j) in self._substrateDissimilarities:
            return self._substrateDissimilarities[(i,j)]
        elif (j,i) in self._substrateDissimilarities:
            return self._substrateDissimilarities[(j,i)]
        
        # Calculate the similarity based on the dissimilarity
        #         d(bS1, S2) = sqrt(sum(b*S1-S2)^2/[2*(sum(b*S1-b*mean(S1))^2 + sum(S2-mean(S2))^2)])
        # (note that d(bS1,S2)==d(S1,S2/b), which ensures symmetry when the similarity is defined as
        #         sim(S1,S2) = 1 - min_b{d(bS1,S2)} = sim(S2,S1)
        sSpan_i = dict([(rid, self.getS(rid)[self._substrates[i]]) for rid in self.getRunIDs()])
        sSpan_j = dict([(rid, self.getS(rid)[self._substrates[j]]) for rid in self.getRunIDs()])
        
        def d_ij(b):
            SSR = sum([sum((sSpan_i[rid]*b - sSpan_j[rid])**2) for rid in self.getRunIDs()])
            SSTi = b*b*sum([sum((sSpan_i[rid] - np.mean(sSpan_i[rid]))**2) for rid in self.getRunIDs()])
            SSTj = b*b*sum([sum((sSpan_j[rid] - np.mean(sSpan_j[rid]))**2) for rid in self.getRunIDs()])
            return np.sqrt(0.5*SSR/(SSTi+SSTj))
        
        # Find minimizing b
        res = minimize(d_ij, [1.0])
        b, d = res.x[0], res.fun
        self._substrateDissimilarities[(i,j)] = d
        return d
    
        
    def buildSubstrateClusters(self, figname=None, similarity_threshold=0.075):
        #print("Called buildClusters()")
        # Generate similarity matrix
        print("\n# Generating substrate similarities ...")
        flattenedDistances = []
        N = len(self._substrates)
        for i in range(N):
            for j in range(i+1, N):
                flattenedDistances.append(self._substrateDissimilarity(i, j))
        self._similarityThreshold = similarity_threshold  # isolates also Man/Nag, and Thre if applied to bounded diameter
        # Plotting cluster dendrogram
        _ = self._makeDendrogram(flattenedDistances, figname, False)
        self._substrateClusters = self._determineSubstrateClusters(flattenedDistances, method="cut_tree")
        
        
def fitInteraction(fitter, substrate, clusterIDs, fitID, fitK=None, useInitialParams=False, load=True):
    print("fitInteraction() %s -> %s, fitK=%s"%([fitter._substrateClusters[cID] for cID in clusterIDs], substrate, fitK))
    fn = os.path.join(TMP_SAVE_DIR, fitID, "interactionfit_result_%s_%s_%s.pickle"%(fitter.getID(), substrate, clusterIDs))
    os.makedirs(Path(fn).parent, exist_ok=True)
    if load and os.path.exists(fn):
        try:
            with open(fn,"rb") as f:
                res = pickle.load(f)
            print("Loaded fit result from '%s'"%fn)
            return res
        except Exception as e:
            print("Failure loading fit result from '%s'"%fn)
            print("Error:\n", str(e))
    res = fitter.fitUptakeParameter(substrate, clusterIDs, fitK=fitK, useInitialParams=useInitialParams)
    with open(fn,"wb") as f:
        pickle.dump(res, f)
    print("Saved fit result to '%s'"%fn)
    return res
        

def fitInteractions(fitter, substrates, nrInteractions, fitID,
                    useInitialParams=False, figdir=None, 
                    cluster_similarity_threshold=0.075,
                    parallel=False):
    if len(fitter.getSubstrates()) <= 1:
        raise Exception("No interaction fitting for single substrate experiments!")
        
    if figdir:
        cluster_figfn = figdir / f"clusters_{fitter._experiment._experimentID}_{fitID}.svg"
    else:
        cluster_figfn = None
    fitter.buildSubstrateClusters(figname = cluster_figfn, similarity_threshold=cluster_similarity_threshold)
    clusters = fitter.getClusters()
    print("clusters:",clusters)
    print("substrates:",substrates)
    
    ARGS = []
    for substrateIndex, substrate in enumerate(substrates):
        if nrInteractions == 1:
            for clusterID, cluster in clusters.items():
                if substrateIndex in cluster:
                    continue # disallow inhibition of elements by their associated cluster
                ARGS.append((fitter, substrate, [clusterID], fitID, fitter._fitK or substrate=="Ile", useInitialParams))
        elif nrInteractions == 2:
            for clusterID, cluster in clusters.items():
                if substrateIndex in cluster:
                    continue # disallow inhibition of elements by their associated cluster
                for clusterID2, cluster2 in clusters.items():
                    if clusterID == clusterID2 or substrateIndex in cluster2:
                        # disallow inhibition of elements by their associated cluster
                        # (and duplicate inhibitions)
                        continue 
                    ARGS.append((fitter, substrate, [clusterID, clusterID2], fitID, fitter._fitK or substrate=="Ile", useInitialParams))
        else:
            raise Exception("Fitting more than two interactions per substrate is not implemented.")
    if parallel:
        pool = mp.Pool(NCPU)
        results = [r for r in pool.starmap(fitInteraction, ARGS)]
    else:
        results = [r for r in starmap(fitInteraction, ARGS)]

    print("res:",results)
    params, errors = {}, {}
    for s in substrates:
        params[s], errors[s] = {}, {}
    for i in range(len(ARGS)):
        s = ARGS[i][1]
        cIDs = tuple(ARGS[i][2])
        res_i = results[i]
        
        params[s][cIDs] = {"mu":res_i["pOpt"]["mu"], "K":res_i["pOpt"]["K"], "a":res_i["pOpt"]["a"], "clusterIndices":[fitter.getClusterIndices(cID) for cID in cIDs]}
        errors[s][cIDs] = {"ssr":res_i["err"]["ssr"], "sst":res_i["err"]["sst"], "r2":1-res_i["err"]["ssr"]/res_i["err"]["sst"]}
        print("s: %s, cIDs: %s"%(s, cIDs))
        print("params:", params[s][cIDs])
        print("errors:", errors[s][cIDs])
            
    print("params:\n", params)
    return params, errors
    

def fitSubstrateUptake(fitter, sid, fitK=None):
    print("Fit substrate '%s' on fitter '%s'"%(sid, fitter.getID()))
    print("fitter._fitK =",fitter._fitK)
    return fitter.fitUptakeParameter(sid, fitK=fitK)
    
## Functions to be called in parallel
def fitUptakeParameter(fitter, initialParams, pool):
    print("initialParams:",initialParams)
    fitter.setUptakeParams(initialParams)
    substrates = fitter._substrates
    ARGS = [(fitter, sid, fitter._fitK or sid=="Ile") for sid in substrates]
    if pool:
        res = pool.starmap_async(fitSubstrateUptake, ARGS)
    else:
        res = [r for r in starmap(fitSubstrateUptake, ARGS)]
    return substrates, res
    

def bestGuessSubstrateParams(fitter, nguesses, lhs_seed=123):
    substrates = fitter._substrates
    nruns = len(fitter.getRunIDs())
    params_base = defaults.makeParams(substrates, nruns)
    
    nsubs = len(substrates)
    
    lhs = LatinHypercube(d=2*nsubs, seed=lhs_seed)
    minK, maxK = 0.01, 25.0
    min_mu, max_mu = 0.01, 25.0
    
    lhs_samples = lhs.random(nguesses)
    
    Ks = minK + lhs_samples[:,:nsubs]*(maxK-minK)
    mus = min_mu + lhs_samples[:,nsubs:]*(max_mu-min_mu)
    candidate_pars = []
    for j in range(nguesses):
        K = Ks[j]
        mu = mus[j]
        for i, s in enumerate(substrates):
            pars = deepcopy(params_base)
            pars[s]["K"]  = K[i]
            pars[s]["mu"] = mu[i]
        candidate_pars.append(pars) 
    
    best_guess = None
    max_R2 = -np.inf
    for pars in candidate_pars:
        sst, ssr = 0.0, 0.0
        for s in substrates:
            err = fitter.getError(s, pars)
            sst += err["sst"]
            ssr += err["ssr"]
        R2 = 1 - ssr/sst
        if R2 > max_R2:
            best_guess = pars
            max_R2 = R2
    return best_guess
    
    

def fitUptakeParameterBatch(fitter, IDs, LHS_presampling=0, parallel=True):
    # call with experiment ID list triggers parallel fitting for given experiments
    # sampled indicates whether this is a fit for synthetic data
    print("fitUptakeParameterBatch() for %s"%IDs)
    parallel = (len(IDs) > 1) and parallel
    if parallel:
        pool = mp.Pool(min(NCPU, len(IDs)))
    else:
        pool = None
    results, params, errors = {}, {}, {}
    for fid in IDs: 
        if LHS_presampling:
            initialParams = bestGuessSubstrateParams(fitter[fid], nguesses=LHS_presampling)
        else:
            initialParams = defaults.makeParams(fitter[fid]._substrates, len(fitter[fid].getRunIDs()), synthetic=fitter[fid]._synthetic)
        if not fitter[fid]._fitK:
            for k,v in initialParams.items():
                if type(v) is dict and "K" in v:
                    del v["K"]            
        results[fid] = fitUptakeParameter(fitter[fid], initialParams, pool)
    
    if pool:
        pool.close()
        pool.join()
        
    for fid in IDs:
        substrates, res = results[fid]
        if pool:
            res = [r for r in res.get()]
        params[fid] = dict([(s,res[i]["pOpt"]) for i,s in enumerate(substrates)])
        errors[fid] = dict([(s,res[i]["err"]) for i,s in enumerate(substrates)])
        print("Uptake parameter fitting result for %s:"%fid)
        print("  parameter values:")
        for k,v in params[fid].items():
            print("    ", k, ":", v)
        print("  errors:")
        for k,v in errors[fid].items():
            print("    ", k, ":", v)
            
    return params, errors


def fitV0(fitter, onlyGrowthDynamics=False):
    fitter.activateInteractions()
    return fitter.fitV0(onlyGrowthDynamics)


def calculateBiomassError(fitter, growthParams, V0):
    fitter.setGrowthParams(growthParams)
    fitter.setV0(V0)
    SSR, SST = 0.0, 0.0
    for rid in fitter.getRunIDs():
        ssr, sst = fitter.residualErrorBiomass(rid)
        SSR += ssr; SST += sst
    nRuns = len(fitter.getRunIDs())
    return SSR/nRuns, SST/nRuns


## Joint fitting of growth parameters over an array of experiments
def fitGrowthParameters(fitters, fitIDs, withInteractions):
    # Assuming that TDA fitting is globally turned on/off (see TDA_FITTING) 
    # we look up the setting only in the first fitter...
    tdaFitting = fitters[fitIDs[0]]._tdaFitting 
    for fitter in fitters.values():
        assert(fitter._tdaFitting == tdaFitting)
        if withInteractions:
            fitter.activateInteractions()
        else:
            fitter.deactivateInteractions()
    
    def Errors(params):
        growthParams = {
            "m" :params[0],
            "rE":params[1],
            "yV":params[2],
            }
        if tdaFitting:
            growthParams["rP"] = params[3]
            growthParams["yP"] = params[4]
            V0_ix = 5
        else:
            V0_ix = 3
        V0 = params[V0_ix:]
        
        V0count = 0
        errors = {} 
        for s in fitIDs:
            runIDs = fitters[s].getRunIDs()
            nRuns = len(runIDs)
            fitters[s].setGrowthParams(growthParams)
            V0_s = dict([(rid, V0[V0count+i]) for i, rid in enumerate(runIDs)])
            fitters[s].setV0(V0_s)
            V0count += nRuns
            
            errors[s] = {"ssr":0.0, "sst":0.0}
            for rid in fitters[s].getRunIDs():
                ssr, sst = fitters[s].residualErrorBiomass(rid)
                errors[s]["ssr"] += ssr
                errors[s]["sst"] += sst 
        return errors
            
    def minusR2(params):
        if np.nanmin(params) < 0: return np.inf
        errors = Errors(params)
        SSR, SST = 0.0, 0.0
        for s, e in errors.items():
            SSR+=e["ssr"]; SST+=e["sst"]
        R2 = 1.0 - SSR/SST
        print("\nParams (m, rE, yV(, rP, yP), [V0]):", params)
        print("R2 (growth, all replicates): %s\n"%R2)
        return -R2
    
    pDef = defaults.growthParams
    p0 = [pDef["m"], pDef["rE"], pDef["yV"]]
    if tdaFitting:
        p0.extend([pDef["rP"], pDef["yP"]])
    nRuns = sum([len(fitters[s].getRunIDs()) for s in fitIDs])
    p0.extend([defaults._defaultV0]*nRuns)
    res = minimize(minusR2, p0, method=OPTIMIZATION_METHOD)
    errors = Errors(res.x)
    
    V0fitted = {}
    V0_ix = 5 if tdaFitting else 3
    for s in fitIDs:
        nRuns_s = len(fitters[s].getRunIDs())
        V0s = zip(fitters[s].getRunIDs(), res.x[V0_ix:V0_ix+nRuns_s])
        V0fitted[s] = dict(V0s)
        V0_ix += nRuns_s
    growthParamsFitted = {"m" :res.x[0], "rE":res.x[1], "yV":res.x[2], "V0":V0fitted}
    if tdaFitting:
        growthParamsFitted["rP"] = res.x[3]
        growthParamsFitted["yP"] = res.x[4]

    return growthParamsFitted, errors
    
    
def selectInteractions(qualifyingRelativeImprovement, qualifyingAbsoluteImprovement, results):
    # params is a map (substrate, cID) -> (mu, K, a, clusterIndices)
    params = results["interactions"]["params"]
    # errors is a map (substrate, cID) -> (sst, ssr)
    errorsI = results["interactions"]["errors"]
    errorsNoI = results["uptake"]["errors"]["mix11"]

    # Determine interactions, which improve the fit most significantly
    R2NoInteraction = {}
    for s, d in errorsNoI.items():
        r2 = 1 - d["ssr"]/d["sst"]
        R2NoInteraction[s] = r2
    
    # For each substrate determine the maximal interaction
    bestParams = {}
    for s, d in errorsI.items():
        bestCluster = None
        bestR2 = 0.0
        for cid, e in d.items():
            if len(cid) > 1:
                # Only use 1-interactions cases
                continue
            r2 = 1 - e["ssr"]/e["sst"]
            if r2 > bestR2:
                bestR2 = r2
                bestCluster = cid    
        bestParams[s] = results["interactions"]["params"][s][bestCluster]
        # Transform into format understood by fitter.setInteractions()
        a = bestParams[s]["a"]
        if np.iterable(a):
            bestParams[s]["a"] = a[0]
        cli = bestParams[s]["clusterIndices"]
        if np.iterable(cli[0]):
            bestParams[s]["clusterIndices"] = cli[0]
        bestParams[s]["cluster"] = bestCluster
        bestParams[s]["r2"] = bestR2
        absoluteImprovement = bestR2 - R2NoInteraction[s]
        relativeImprovement = absoluteImprovement/(1 - R2NoInteraction[s])
        bestParams[s]["Improvement R2 abs"] = absoluteImprovement
        bestParams[s]["Improvement R2 rel"] = relativeImprovement
        
    selectedInteractions = dict([(s, [d]) for s,d in bestParams.items() if 
                                 (d["Improvement R2 rel"] >= qualifyingRelativeImprovement) and
                                (d["Improvement R2 abs"] >= qualifyingAbsoluteImprovement)])
    
    print(f"\nSelected Interactions (qrel={qualifyingRelativeImprovement}, qabs={qualifyingAbsoluteImprovement}):")
    pp(selectedInteractions)
    return selectedInteractions, bestParams


def fullResidualError(fitter:DEBFitter, rid):
    return fitter.residualErrorFull(rid)

    
def fitFullModel(fitter, fitInteractions=True, recompute=False):
    # This neglects TDA fitting
    assert(not fitter._tdaFitting)
    nSubstrates = len(fitter.getSubstrates())
    if fitInteractions:
        fitter.activateInteractions()
        interactions = fitter.getInteractions()
        nInteractions = len(interactions) # assuming at max 1 interaction per substrate
        interactionSubs = sorted(interactions)
        clusterIndices = [interactions[s][0]["clusterIndices"] for s in interactionSubs]
        interactionStrengthsInit = [interactions[s][0]["a"] for s in interactionSubs]
    else:
        fitter.deactivateInteractions()
        nInteractions = 0
    interactionStrengthIndex = nSubstrates*2 + 3
    V0Index = nSubstrates*2 + 3 + nInteractions
    
    def Errors(params):
        growthParams = {
            "m" :params[0],
            "rE":params[1],
            "yV":params[2]
            }
        uptakeParams = {
            "K"  : params[nSubstrates+3:2*nSubstrates+3],
            "mu" : params[3:nSubstrates+3]
            }
        V0 = dict(zip(fitter.getRunIDs(), params[V0Index:]))
        if fitInteractions:
            ints = {s: [dict(clusterIndices=clusterIndices[i], 
                                               a=params[interactionStrengthIndex+i])]
                                          for i, s in enumerate(interactionSubs)}
            fitter.setInteractions(ints)

        print("growthParams:", growthParams)
        print("uptakeParams:", uptakeParams)
        if fitInteractions:
            print("interactions:")
            pp(ints)
        print("V0:",V0)
        
        fitter.setGrowthParams(growthParams)
        fitter.setUptakeParams(uptakeParams)
        fitter.setV0(V0)
       
        # calculate residual errors of different runs in serial (seems faster than parallel...)  
        res=[]
        for rid in fitter.getRunIDs():
            res.append(fullResidualError(fitter, rid))
        
        # Return total errors                
        ssr, sst = 0.0, 0.0
        for i in res:
            ssr += i[0]
            sst += i[1]
        return ssr, sst
            
    def minusR2(params):
        if np.nanmin(params) < 0: return np.inf
        SSR, SST = Errors(params)
        R2 = 1.0 - SSR/SST
        print("R2 (full model): %s\n"%R2)
        return -R2
    
    # Initial parameters are taken as original values stored in the fitter object
    p = fitter.getUptakeParams()
    print("fitter.getUptakeParams():",p)
    uptakeParams0 = np.hstack((p["mu"], p["K"]))
    p = fitter.getGrowthParams()
    print("fitter.getGrowthParams():",p)
    growthParams0 = [p["m"], p["rE"], p["yV"]]
    params0 = np.hstack((growthParams0, uptakeParams0))
    if fitInteractions:
        params0 = np.hstack((params0, interactionStrengthsInit))
    for rid in fitter.getRunIDs(): params0 = np.hstack((params0, fitter.getV0(rid)))
    
    #res = minimize(minusR2, params0, method=OPTIMIZATION_METHOD)
    print("params0:",params0)
    res = minimize(minusR2, params0, method="Nelder-Mead")
    ssr, sst = Errors(res.x) 
    
    # Transform parameter vector into parameter and error dicts
    errors = {"ssr":ssr, "sst":sst}
    params = {
            "m"  : res.x[0],
            "rE" : res.x[1],
            "yV" : res.x[2],
            "K"  : res.x[nSubstrates+3:2*nSubstrates+3],
            "mu" : res.x[3:nSubstrates+3],
            "V0" : res.x[V0Index:],
        }
    
    if fitInteractions:
        aopt = res.x[interactionStrengthIndex:interactionStrengthIndex+nInteractions]
        params["interactions"] = {s : [(clusterIndices[i], aopt[i])] for i, s in enumerate(interactionSubs)}
    
    return params, errors
    
    
def getIxMinAndIxMax(exp, thresh):
    ''' Computes the per run indices for minimal t such that CDW(t) > thresh
        and for maximal CDW 
    '''
    ixMaxGrowth = {}
    ixMinRates = {}
    
    for rid in exp._runIDs:
        if rid in exp._cdwodSpan:
            # Use CDWOD
            ixMinRates[rid] = np.nanargmax(exp._cdwodSpan[rid] >= thresh)
            ixMaxGrowth[rid] = np.nanargmax(exp._cdwodSpan[rid])+1
        else:
            # Use CDW
            ixMinRates[rid] = np.nanargmax(exp._cdwSpan[rid] >= thresh)
            ixMaxGrowth[rid] = np.nanargmax(exp._cdwSpan[rid])+1
    return ixMinRates, ixMaxGrowth
    

def calculate_best_fit_scores(data, inhibited):
    dfs = data.loc[data["substrate"] == inhibited]
    dfs0 = dfs.loc[dfs["nrInteractions"] == 0]
    dfs1 = dfs.loc[dfs["nrInteractions"] == 1]
    dfs2 = dfs.loc[dfs["nrInteractions"] == 2]

    R20 = np.array(dfs0["R2"])[0]
    ssr0 = np.array(dfs0["ssr"])[0]
    
    if not dfs1.empty:
        ssr1 = np.array(dfs1["ssr"])
        redux1 = np.maximum(0.0, (ssr0 - ssr1)/ssr0)
        improve1 = np.maximum(0.0, (ssr0 - ssr1)/(1-ssr0))
        R21 = np.max([np.max(dfs1["R2"]), R20])
        ssr1 = np.min([np.min(ssr1), ssr0])
        dfs1_best = dfs1.loc[dfs1["R2"] == np.max(dfs1["R2"])] 
        best_interaction1 = np.array(dfs1_best["interactions"])[0]
        dR21 = R21-R20
        a1 = np.sum(dfs1_best["a"])
    else:
        R21 = dR21 = np.nan
        redux1 = improve1 = ssr1 = [np.nan]
        best_interaction1 = "NA"
        a1 = np.nan

    if not (dfs1.empty or dfs2.empty): 
        ssr2 = np.array(dfs2["ssr"])
        redux2 = np.maximum(0.0, (ssr1 - ssr2)/ssr1)
        improve2 = np.maximum(0.0, (ssr1 - ssr2)/(1-ssr1))
        R22 = np.max([np.max(dfs2["R2"]), R21])
        ssr2 = np.min([np.min(ssr2), ssr0])
        dfs2_best = dfs2.loc[dfs2["R2"] == np.max(dfs2["R2"])] 
        best_interaction2 = np.array(dfs2_best["interactions"])[0]
        dR22 = R22-R21
        a2 = np.sum(dfs2_best["a"])
    else:
        # (even if first interaction of chain not included, scores for second cannot be computed)
        R22 = dR22 = np.nan
        redux2 = improve2 = ssr2 = [np.nan]
        best_interaction2 = "NA"
        a2 = np.nan

    return (best_interaction1, best_interaction2, 
            R20, R21, R22, ssr0, ssr1, ssr2, dR21, dR22, a1, a2,
            redux1, redux2, improve1, improve2)


def calculate_fit_scores(data, inhibited, inhibition1, inhibition2):
    assert(inhibition1 == "NA" or len(inhibition1) == 1)
    assert(inhibition2 == "NA" or len(inhibition2) == 2)
    
    # In order to calculate the improvement for a specific interaction,
    # we discard all others and calculate the best improvements.
    data = data.loc[([i == None for i in data["interactions"]]) | (data["interactions"] == inhibition1)  | (data["interactions"] == inhibition2)]
    return calculate_best_fit_scores(data, inhibited)


def make_result_dataframe(results, fitter, resampling_results=None):
    df = {"substrate":[], # inhibited substrate
          "interactions":[], # label for interactions considered in this fit
          "nrInteractions":[], # number of interactions
          "R2":[], 
          "sst":[],
          "ssr":[],
          "a": [],
          }
    if resampling_results:
        df["rel. error reduction"] = []
        df["rel. fit improvement"] = []
        df["dR2"] = []
    
    R20, SSR0 = {}, {}
    for k,v in results["uptake"]["errors"]["mix11"].items():
        df["substrate"].append(k)
        df["interactions"].append(None)
        df["nrInteractions"].append(0)
        df["ssr"].append(v["ssr"])
        df["sst"].append(v["sst"])
        R2 = 1-v["ssr"]/v["sst"]
        df["R2"].append(R2)
        R20[k] = R2
        SSR0[k] = v["ssr"]
        df["a"].append(None)
        if resampling_results:
            df["rel. error reduction"].append(0.0)
            df["rel. fit improvement"].append(0.0)
            df["dR2"].append(0.0)

    for sid,d in results["interactions"]["errors"].items():
        for cid,v in d.items():
            p = results["interactions"]["params"][sid][cid]
            six = fitter.getSubstrateIx(sid)
            self_inhibition = np.any([(six in cx) if np.iterable(cx) else six==cx for cx in p["clusterIndices"]])
            if self_inhibition:
                continue
            df["substrate"].append(sid)
            df["interactions"].append(cid)
            df["nrInteractions"].append(len(cid))
            df["ssr"].append(v["ssr"])
            df["sst"].append(v["sst"])
            R2 = 1-v["ssr"]/v["sst"]
            df["R2"].append(R2)
            df["a"].append(p["a"])
            if resampling_results:
                redux = np.maximum(0.0, (SSR0[sid] - v["ssr"])/SSR0[sid])
                improve = np.maximum(0.0, (SSR0[sid] - v["ssr"])/(1-SSR0[sid]))
                df["rel. error reduction"].append(max(0.0, redux))
                df["rel. fit improvement"].append(max(0.0, improve))
                df["dR2"].append(max(0.0, R2-R20[sid]))
    df = pd.DataFrame(df)
    return df


def addResamplingAnalysis(df, resampling_results, fitter, sid, interaction1, interaction2):
    resampled_scores = defaultdict(list)
    for omitted, res in resampling_results.items():
        df_re = make_result_dataframe(res, fitter)
        (best_interaction1_re, best_interaction2_re, 
        R20_re, R21_re, R22_re, ssr0_re, ssr1_re, ssr2_re, dR21_re, dR22_re, a1, a2,
        redux1_re, redux2_re, improve1_re, improve2_re) = calculate_fit_scores(df_re, sid, interaction1, interaction2)
        resampled_scores["omit"].append(omitted)
        resampled_scores["R20"].append(R20_re)
        resampled_scores["R21"].append(R21_re)
        resampled_scores["R22"].append(R22_re)
        resampled_scores["redux1"].append(redux1_re)
        resampled_scores["redux2"].append(redux2_re)
        resampled_scores["improve1"].append(improve1_re)
        resampled_scores["improve2"].append(improve2_re)
        resampled_scores["dR21"].append(dR21_re)
        resampled_scores["dR22"].append(dR22_re)
        resampled_scores["R20"].append(R20_re)
        resampled_scores["R21"].append(R21_re)
        resampled_scores["R22"].append(R22_re)
        resampled_scores["a1"].append(np.sum(a1))
        resampled_scores["a2"].append(np.sum(a2))

    print("Resampled scores:")
    pp(resampled_scores)

    if type(df) == dict:
        # this is called in the context of buiding up df_best
        df["mean(q)"].extend(
            [None, np.nanmean(resampled_scores["redux1"]), np.nanmean(resampled_scores["redux2"])])
        df["mean(p)"].extend(
            [None, np.nanmean(resampled_scores["improve1"]), np.nanmean(resampled_scores["improve2"])])
        df["mean(dR2)"].extend(
            [None, np.nanmean(resampled_scores["dR21"]), np.nanmean(resampled_scores["dR22"])])
        df["mean(R2)"].extend(
            [np.nanmean(resampled_scores["R20"]), np.nanmean(resampled_scores["R21"]), np.nanmean(resampled_scores["R22"])])
        df["mean(a)"].extend(
            [None, np.nanstd(resampled_scores["a1"]), np.nanstd(resampled_scores["a2"])])
        df["std(q)"].extend(
            [None, np.nanstd(resampled_scores["redux1"]), np.nanstd(resampled_scores["redux2"])])
        df["std(p)"].extend(
            [None, np.nanstd(resampled_scores["improve1"]), np.nanstd(resampled_scores["improve2"])])
        df["std(R2)"].extend(
            [np.nanstd(resampled_scores["R20"]), np.nanstd(resampled_scores["R21"]), np.nanstd(resampled_scores["R22"])])
        df["std(dR2)"].extend(
            [None, np.nanstd(resampled_scores["dR21"]), np.nanstd(resampled_scores["dR22"])])
        df["std(a)"].extend(
            [None, np.nanstd(resampled_scores["a1"]), np.nanstd(resampled_scores["a2"])])
        df["min(a)"].extend(
            [None, np.nanmin(resampled_scores["a1"]), np.nanmin(resampled_scores["a2"])])
        df["max(a)"].extend(
            [None, np.nanmax(resampled_scores["a1"]), np.nanmax(resampled_scores["a2"])])
    else:
        # This is called to enrich an existing df_all DataFrame
        df_all, iloc = df
        assert(type(df_all) == pd.DataFrame)
        assert(sum(iloc)==2)
        df_all.loc[iloc, "mean(q)"] = [np.nan, np.nanmean(resampled_scores["redux1"])]
        df_all.loc[iloc, "mean(p)"] = [np.nan, np.nanmean(resampled_scores["improve1"])]
        df_all.loc[iloc, "mean(dR2)"] = [np.nan, np.nanmean(resampled_scores["dR21"])]
        df_all.loc[iloc, "mean(R2)"] = [np.nanmean(resampled_scores["R20"]), np.nanmean(resampled_scores["R21"])]
        df_all.loc[iloc, "mean(a)"] = [np.nan, np.nanmean(resampled_scores["a1"])]
        df_all.loc[iloc, "min(a)"] = [np.nan, np.nanmin(resampled_scores["a1"])]
        df_all.loc[iloc, "max(a)"] = [np.nan, np.nanmax(resampled_scores["a1"])]
        df_all.loc[iloc, "std(q)"] = [np.nan, np.nanstd(resampled_scores["redux1"])]
        df_all.loc[iloc, "std(p)"] = [np.nan, np.nanstd(resampled_scores["improve1"])]
        df_all.loc[iloc, "std(R2)"] = [np.nanstd(resampled_scores["R20"]), np.nanstd(resampled_scores["R21"])]
        df_all.loc[iloc, "std(dR2)"] = [np.nan, np.nanstd(resampled_scores["dR21"])]
        df_all.loc[iloc, "std(a)"] = [np.nan, np.nanstd(resampled_scores["a1"])]




def addScoresAndConfidence(df, fitter, resampling_results, substrates=[]):
    if substrates == []:
        substrates = pd.unique(df["substrate"])
    clusters = sorted(set([c[0] for c in df["interactions"] if c is not None and len(c)==1]))
    for sid in substrates:
        loc_s = np.array(df["substrate"] == sid)
        loc_i0 = np.array(df["nrInteractions"] == 0)
        loc_i1 = np.array(df["nrInteractions"] == 1)
        dfs0 = df.iloc[loc_s & loc_i0]
        R20 = np.array(dfs0["R2"])[0]
        ssr0 = np.array(dfs0["ssr"])[0]

        # Add scores for one interaction
        for cid in clusters:
            if sid in [fitter.getSubstrates()[six] for six in fitter.getClusters()[cid]]:
                continue
            loc_c = np.array(df["interactions"]==(cid,))
            loc_sc = loc_s & loc_c
            ssr1 = np.array(df.iloc[loc_sc]["ssr"])[0]
            R21 = np.array(df.iloc[loc_sc]["R2"])[0]
            dR2 = R21-R20
            redux1 = np.maximum(0.0, (ssr0 - ssr1)/ssr0)
            improve1 = np.maximum(0.0, (ssr0 - ssr1)/(1-ssr0))
            df.iloc[loc_sc]["rel. fit improvement"] = improve1
            df.iloc[loc_sc]["rel. error reduction"] = redux1
            df.iloc[loc_sc]["dR2"] = dR2
            loc_sc2 = loc_s & (loc_c | loc_i0)
            addResamplingAnalysis((df, loc_sc2), resampling_results, fitter, sid, (cid,), "NA")


def bestFitInformation(fitter, results, resampling_results=None):
    ''' Construct a dataframe containing
        the best fits per substrate and 
        number of interactions
    '''
    clusters = sorted(fitter.getClusters())

    df = make_result_dataframe(results, fitter, resampling_results)
    
    # Best interactions per substrate and per 
    df_best = {"substrate":[], # inhibited substrate
          "interactions":[], # label for interactions considered in this fit
          "nrInteractions":[], # number of interactions
          "R2":[], 
          "sst":[],
          "ssr":[],
          "rel. error reduction":[],
          "err. reduction variance":[],
          "err. reduction mean":[],
          "rel. fit improvement":[],
          "fit improvement variance":[],
          "fit improvement mean":[],
          "dR2":[],
          "a":[],
          "R2 variance":[],
          "R2 mean":[],
          }
    if resampling_results:
        df_best.update(
                {"mean(q)":[], "mean(p)":[], "mean(R2)":[], "mean(dR2)":[],  "mean(a)":[],
                "std(q)":[], "std(p)":[], "std(R2)":[], "std(dR2)":[], "std(a)":[], "min(a)":[], "max(a)":[]})
        # Add columns to df
        for k in df_best:
            if k not in df.columns:
                df.loc[:,k] = np.nan
        # We only use Glc, later
        # addScoresAndConfidence(df, fitter, resampling_results, substrates=["Glc"])
        # Calculate all
        addScoresAndConfidence(df, fitter, resampling_results)


    substrates = pd.unique(df["substrate"])
    for sid in substrates:
        dfs = df.loc[df["substrate"] == sid]
        dfs0 = dfs.loc[dfs["nrInteractions"] == 0]
        dfs1 = dfs.loc[dfs["nrInteractions"] == 1]
        dfs2 = dfs.loc[dfs["nrInteractions"] == 2]

        (best_interaction1, best_interaction2, 
         R20, R21, R22, ssr0, ssr1, ssr2, dR21, dR22, a1, a2,
         redux1, redux2, improve1, improve2) = calculate_best_fit_scores(df, sid)
        
        dfs1_best = dfs1.loc[dfs1["interactions"]==best_interaction1]
        dfs2_best = dfs2.loc[dfs2["interactions"]==best_interaction2]

        # Without interaction
        df_best["substrate"].extend([sid]*3)
        df_best["nrInteractions"].extend([0,1,2])
        df_best["interactions"].extend([None, best_interaction1, best_interaction2])
        df_best["ssr"].extend([ssr0, ssr1, ssr2])
        df_best["sst"].extend([np.array(dfs0["sst"])[0], np.array(dfs1_best["sst"])[0], np.array(dfs2_best["sst"])[0]])
        df_best["R2"].extend([R20, R21, R22])
        df_best["rel. error reduction"].extend([None, np.max(redux1), np.max(redux2)])
        var1, mean1 = np.var(redux1), np.mean(redux1)
        var2, mean2 = np.var(redux2), np.mean(redux2)
        df_best["err. reduction variance"].extend([None, var1, var2])
        df_best["err. reduction mean"].extend([None, mean1, mean2])
        df_best["rel. fit improvement"].extend([None, np.max(improve1), np.max(improve2)])
        var1_imp, mean1_imp = np.var(improve1), np.mean(improve1)
        var2_imp, mean2_imp = np.var(improve2), np.mean(improve1)
        df_best["fit improvement variance"].extend([None, var1_imp, var2_imp])
        df_best["fit improvement mean"].extend([None, mean1_imp, mean2_imp])
        var1, mean1 = np.var(dfs1["R2"]), np.mean(dfs1["R2"])
        var2, mean2 = np.var(dfs2["R2"]), np.mean(dfs2["R2"])
        df_best["R2 variance"].extend([0.0, var1, var2])
        df_best["R2 mean"].extend([R20, mean1, mean2])
        df_best["dR2"].extend([0.0, dR21, dR22])
        df_best["a"].extend([None, a1, a2])
        if resampling_results:
            # Calculate error bars for scores
            addResamplingAnalysis(df_best, resampling_results, fitter, sid, best_interaction1, best_interaction2)
    df_best = pd.DataFrame(df_best)
    return df_best, df
    
